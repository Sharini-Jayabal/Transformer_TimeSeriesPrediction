import torch
import torch.nn as nn
import numpy as np
import scipy.io
import matplotlib.pyplot as plt

class TransformerEncoderDecoder(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads, sequence_length, dropout=0.1):
        super().__init__()
        self.sequence_length = sequence_length
        self.encoder_layer = nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size, dropout=dropout)
        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)
        self.decoder_layer = nn.TransformerDecoderLayer(hidden_size, num_heads, output_size, dropout=dropout)
        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers)
        self.linear = nn.Linear(hidden_size, output_size)
        self.output_size = output_size 
        self.input_size = input_size
        self.hidden_size = hidden_size

    def forward(self, x):
        x = x.permute(1, 0, 2)  # Swap dimensions 0 and 1
        encoder_output = self.encoder(x)
        x = self.decoder(x, encoder_output)  # Pass the encoder output as memory to the decoder
        x = x.permute(1, 0, 2)  # Swap dimensions 0 and 1 back to the original order
        x = self.linear(x[:, -1, :])
        return x


data = scipy.io.loadmat('/content/gripper_data.mat')
gripper_pos = data['gripper_data_']

# Define the trajectories
trajectories = gripper_pos[:, :, :]

# Define the sequence length and train/test split
sequence_length = 50

# Shuffle the trajectories
np.random.shuffle(trajectories)

# Split the shuffled array into training and testing sets
train_data = trajectories[:,:,:40]
test_data = trajectories[:,:,40:]

# Reshape train_data and test_data
train_data = train_data.transpose(2, 0, 1)  # Shape: (40, 490, 3)
test_data = test_data.transpose(2, 0, 1)  # Shape: (4, 490, 3)

# Normalize the data
train_mean = np.mean(train_data, axis=(1, 2), keepdims=True)
train_std = np.std(train_data, axis=(1, 2), keepdims=True)
train_std += 1e-8
train_data = (train_data - train_mean) / train_std
# Compute mean and standard deviation for the test data
test_mean = np.mean(test_data, axis=(1, 2), keepdims=True)
test_std = np.std(test_data, axis=(1, 2), keepdims=True)
test_std += 1e-8

# Normalize the test data using the mean and standard deviation of the train data
test_data = (test_data - test_mean) / test_std

# Convert the data to PyTorch tensors
X_train = torch.tensor(train_data, dtype=torch.float32)
y_train = torch.tensor(train_data[:, -1, :], dtype=torch.float32)
X_test = torch.tensor(test_data, dtype=torch.float32)
y_test = torch.tensor(test_data[:, -1, :], dtype=torch.float32)

# Defining hyperparameters
input_size = train_data.shape[2]
hidden_size = 3 # Adjusted to the expected embedding dimension
output_size = y_train.shape[1]
num_layers = 2
num_heads = 3
batch_size = 10
num_epochs = 50
learning_rate = 0.1
dropout = 0.5

model = TransformerEncoderDecoder(input_size, hidden_size, output_size, num_layers, num_heads, sequence_length, dropout=dropout)
criterion = nn.MSELoss()  # MSE loss function
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
train_losses = []
test_losses = []
predictions = []
ground_truths = []

for epoch in range(num_epochs):
    # Training phase
    model.train()  # Set the model in training mode
    for i in range(0, len(X_train), batch_size):
        x_batch = X_train[i:i+batch_size]
        y_batch = y_train[i:i+batch_size]
        y_pred = model(x_batch)
        loss = criterion(y_pred[:, 0], y_batch[:, 0])
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_losses.append(loss.item())
        predictions.append(y_pred.detach().numpy())
        ground_truths.append(y_batch.detach().numpy())

    # Evaluation phase
    model.eval()  
    with torch.no_grad():
        test_loss = 0
        for i in range(0, len(X_test), batch_size):
            x_batch = X_test[i:i+batch_size]
            y_batch = y_test[i:i+batch_size]
            y_pred = model(x_batch)
            loss = criterion(y_pred[:, 0], y_batch[:, 0])
            test_loss += loss.item()
            predictions.append(y_pred.detach().numpy())
            ground_truths.append(y_batch.detach().numpy())

        test_losses.append(test_loss)

    # Print the loss values after every 10 epochs
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}, train loss: {train_losses[-1]:.4f}, test loss: {test_losses[-1]:.4f}")

predictions = np.concatenate(predictions)
ground_truths = np.concatenate(ground_truths)

# Plotting the predicted and ground truth values
fig, ax = plt.subplots(figsize=(10, 5))
new_prediction = [0, 50, 100, 150, 200, 250]
all_predictions = np.concatenate([predictions[:490, 0], new_prediction])
ax.plot(all_predictions, label='Predicted', color='cyan')
new_groundtruths = [0, 50, 100, 150, 200, 250]
all_groundtruths = np.concatenate([ground_truths[:490, 0], new_groundtruths])
ax.plot(all_groundtruths, label='Ground Truth', color='green')
ax.set_xlabel('Time step')
ax.set_ylabel(f'Gripper position (coordinate)')
ax.legend()
plt.show()




